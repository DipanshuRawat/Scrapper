# ğŸ—ˆï¸ URL Scraper Project â€” JSON Data 

This project scrapes a website URL, generates:
- `scraped_data.json` â€” Structured data (Title, Meta Description)
- `screenshot.png` â€” Screenshot of the website page

It uses:
- **Node.js + Puppeteer + Chromium** for scraping
- **Python + Flask** for hosting 
- **Poetry** for python dependencies and for creating venv
- **Docker (Multi-Stage Build)** for containerization

---

## ğŸ‘¢ï¸ Project Structure

```plaintext
url-scraper/
â”œâ”€â”€ apt.txt               # Linux packages needed (e.g., Chromium)
â”œâ”€â”€ Dockerfile            # Multi-stage Dockerfile (Node and Python)
â”œâ”€â”€ pyproject.toml        # Python dependencies (Poetry)
â”œâ”€â”€ poetry.lock           # Python dependency lock
â””â”€â”€ src/
    â”œâ”€â”€ node/
    â”‚   â”œâ”€â”€ scrape.js              # Puppeteer script (scrapes data and takes screenshot)
    â”‚   â”œâ”€â”€ package.json            # Node.js project file
    â”‚   â”œâ”€â”€ package-lock.json      
    â”‚   
    â””â”€â”€ python/
        â””â”€â”€ server.py               # Flask server to serve JSON data
```

---

## ğŸ› ï¸ Setup Instructions

### Step 1: Build Docker Image

```bash
docker build -t my-scraper-flask-app .
```

### Step 2: Run Docker Container

Run with a custom URL (e.g., facebook.com):

```bash
docker run -p 5000:5000 -e SCRAPE_URL="https://facebook.com" my-scraper-flask-app
```
- You can set default url in scrape.js.
---

## ğŸŒ Accessing the Outputs

### 1. Access Scraped JSON Data

After container is running:

- Open browser and go to:
  ```
  http://localhost:5000/
  ```

  ![Terminal](image.png)
  
- You will see the JSON response like:

```json
{
  "title": "Facebook â€“ log in or sign up",
  "description": "Connect with friends and the world around you on Facebook."
}
```

---

## ğŸ”¥ Technologies Used

- Node.js 18 (Puppeteer)
- Python 3.10 (Flask)
- Docker (Multi-stage build)

---

## ğŸ­¹ Important Reminders

- If you change the code (`scrape.js` or `server.py`), rebuild the Docker image:
  ```bash
  docker build -t my-scraper-flask-app .
  ```
- Always pass a **proper full URL** (starting with `https://`).

---

## ğŸ“¢ Final Notes

This project demonstrates full-stack scraping + hosting via a single Docker container using Node.js and Python together.

